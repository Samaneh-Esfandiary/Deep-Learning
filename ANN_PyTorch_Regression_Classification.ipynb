{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artificial Neural Network - REGRESSION\n",
    "\n",
    "\n",
    "https://www.kaggle.com/datasets/anandaramg/taxi-trip-data-nyc\n",
    "\n",
    "I'll combine continuous and categorical data to perform a regression and after that Classification. The goal is to estimate the cost of a New York City cab ride from several inputs. \n",
    "\n",
    "\n",
    "Here I am working with tabular data (spreadsheets, SQL tables, etc.) with columns of values that may or may not be relevant. As it happens, neural networks can learn to make connections. However, to do this I have to handle categorical values separately from continuous ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the NYC Taxi Fares dataset\n",
    "\n",
    "\n",
    "The Kaggle competition provides a dataset with about 55 million records. The data contains only the pickup date & time, the latitude & longitude (GPS coordinates) of the pickup and dropoff locations, and the number of passengers. It is up to the contest participant to extract any further information. For instance, does the time of day matter? The day of the week? How do we determine the distance traveled from pairs of GPS coordinates?\n",
    "\n",
    "I used the 120,000 records from April 11 to April 24, 2010. The records are randomly sorted. I'll show how to calculate distance from GPS coordinates, and how to create a pandas datatime object from a text column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>fare_class</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-04-19 08:17:56 UTC</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.992365</td>\n",
       "      <td>40.730521</td>\n",
       "      <td>-73.975499</td>\n",
       "      <td>40.744746</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-04-17 15:43:53 UTC</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.990078</td>\n",
       "      <td>40.740558</td>\n",
       "      <td>-73.974232</td>\n",
       "      <td>40.744114</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-04-17 11:23:26 UTC</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.994149</td>\n",
       "      <td>40.751118</td>\n",
       "      <td>-73.960064</td>\n",
       "      <td>40.766235</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-04-11 21:25:03 UTC</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.990485</td>\n",
       "      <td>40.756422</td>\n",
       "      <td>-73.971205</td>\n",
       "      <td>40.748192</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-04-17 02:19:01 UTC</td>\n",
       "      <td>19.7</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.990976</td>\n",
       "      <td>40.734202</td>\n",
       "      <td>-73.905956</td>\n",
       "      <td>40.743115</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pickup_datetime  fare_amount  fare_class  pickup_longitude  \\\n",
       "0  2010-04-19 08:17:56 UTC          6.5           0        -73.992365   \n",
       "1  2010-04-17 15:43:53 UTC          6.9           0        -73.990078   \n",
       "2  2010-04-17 11:23:26 UTC         10.1           1        -73.994149   \n",
       "3  2010-04-11 21:25:03 UTC          8.9           0        -73.990485   \n",
       "4  2010-04-17 02:19:01 UTC         19.7           1        -73.990976   \n",
       "\n",
       "   pickup_latitude  dropoff_longitude  dropoff_latitude  passenger_count  \n",
       "0        40.730521         -73.975499         40.744746                1  \n",
       "1        40.740558         -73.974232         40.744114                1  \n",
       "2        40.751118         -73.960064         40.766235                2  \n",
       "3        40.756422         -73.971205         40.748192                1  \n",
       "4        40.734202         -73.905956         40.743115                1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../Data/NYCTaxiFares.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    120000.000000\n",
       "mean         10.040326\n",
       "std           7.500134\n",
       "min           2.500000\n",
       "25%           5.700000\n",
       "50%           7.700000\n",
       "75%          11.300000\n",
       "max          49.900000\n",
       "Name: fare_amount, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['fare_amount'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this we see that fares range from \\\\$2.50 to \\\\$49.90, with a mean of \\\\$10.04 and a median of \\\\$7.70"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the distance traveled\n",
    "\n",
    "The <a href='https://en.wikipedia.org/wiki/Haversine_formula'>haversine formula</a> calculates the distance on a sphere between two sets of GPS coordinates.<br>\n",
    "Here we assign latitude values with $\\varphi$ (phi) and longitude with $\\lambda$ (lambda).\n",
    "\n",
    "The distance formula works out to\n",
    "\n",
    "${\\displaystyle d=2r\\arcsin \\left({\\sqrt {\\sin ^{2}\\left({\\frac {\\varphi _{2}-\\varphi _{1}}{2}}\\right)+\\cos(\\varphi _{1})\\:\\cos(\\varphi _{2})\\:\\sin ^{2}\\left({\\frac {\\lambda _{2}-\\lambda _{1}}{2}}\\right)}}\\right)}$\n",
    "\n",
    "where\n",
    "\n",
    "$\\begin{split} r&: \\textrm {radius of the sphere (Earth's radius averages 6371 km)}\\\\\n",
    "\\varphi_1, \\varphi_2&: \\textrm {latitudes of point 1 and point 2}\\\\\n",
    "\\lambda_1, \\lambda_2&: \\textrm {longitudes of point 1 and point 2}\\end{split}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_distance(df, lat1, long1, lat2, long2):\n",
    "    \"\"\"\n",
    "    Calculates the haversine distance between 2 sets of GPS coordinates in df\n",
    "    \"\"\"\n",
    "    r = 6371  # average radius of Earth in kilometers\n",
    "       \n",
    "    phi1 = np.radians(df[lat1])\n",
    "    phi2 = np.radians(df[lat2])\n",
    "    \n",
    "    delta_phi = np.radians(df[lat2]-df[lat1])\n",
    "    delta_lambda = np.radians(df[long2]-df[long1])\n",
    "     \n",
    "    a = np.sin(delta_phi/2)**2 + np.cos(phi1) * np.cos(phi2) * np.sin(delta_lambda/2)**2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n",
    "    d = (r * c) # in kilometers\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>fare_class</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>dist_km</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-04-19 08:17:56 UTC</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.992365</td>\n",
       "      <td>40.730521</td>\n",
       "      <td>-73.975499</td>\n",
       "      <td>40.744746</td>\n",
       "      <td>1</td>\n",
       "      <td>2.126312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-04-17 15:43:53 UTC</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.990078</td>\n",
       "      <td>40.740558</td>\n",
       "      <td>-73.974232</td>\n",
       "      <td>40.744114</td>\n",
       "      <td>1</td>\n",
       "      <td>1.392307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-04-17 11:23:26 UTC</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.994149</td>\n",
       "      <td>40.751118</td>\n",
       "      <td>-73.960064</td>\n",
       "      <td>40.766235</td>\n",
       "      <td>2</td>\n",
       "      <td>3.326763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-04-11 21:25:03 UTC</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.990485</td>\n",
       "      <td>40.756422</td>\n",
       "      <td>-73.971205</td>\n",
       "      <td>40.748192</td>\n",
       "      <td>1</td>\n",
       "      <td>1.864129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-04-17 02:19:01 UTC</td>\n",
       "      <td>19.7</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.990976</td>\n",
       "      <td>40.734202</td>\n",
       "      <td>-73.905956</td>\n",
       "      <td>40.743115</td>\n",
       "      <td>1</td>\n",
       "      <td>7.231321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pickup_datetime  fare_amount  fare_class  pickup_longitude  \\\n",
       "0  2010-04-19 08:17:56 UTC          6.5           0        -73.992365   \n",
       "1  2010-04-17 15:43:53 UTC          6.9           0        -73.990078   \n",
       "2  2010-04-17 11:23:26 UTC         10.1           1        -73.994149   \n",
       "3  2010-04-11 21:25:03 UTC          8.9           0        -73.990485   \n",
       "4  2010-04-17 02:19:01 UTC         19.7           1        -73.990976   \n",
       "\n",
       "   pickup_latitude  dropoff_longitude  dropoff_latitude  passenger_count  \\\n",
       "0        40.730521         -73.975499         40.744746                1   \n",
       "1        40.740558         -73.974232         40.744114                1   \n",
       "2        40.751118         -73.960064         40.766235                2   \n",
       "3        40.756422         -73.971205         40.748192                1   \n",
       "4        40.734202         -73.905956         40.743115                1   \n",
       "\n",
       "    dist_km  \n",
       "0  2.126312  \n",
       "1  1.392307  \n",
       "2  3.326763  \n",
       "3  1.864129  \n",
       "4  7.231321  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['dist_km'] = haversine_distance(df,'pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 120000 entries, 0 to 119999\n",
      "Data columns (total 9 columns):\n",
      "pickup_datetime      120000 non-null object\n",
      "fare_amount          120000 non-null float64\n",
      "fare_class           120000 non-null int64\n",
      "pickup_longitude     120000 non-null float64\n",
      "pickup_latitude      120000 non-null float64\n",
      "dropoff_longitude    120000 non-null float64\n",
      "dropoff_latitude     120000 non-null float64\n",
      "passenger_count      120000 non-null int64\n",
      "dist_km              120000 non-null float64\n",
      "dtypes: float64(6), int64(2), object(1)\n",
      "memory usage: 8.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add a datetime column and derive useful statistics\n",
    "\n",
    "\n",
    "By creating a datetime object, we can extract information like \"day of the week\", \"am vs. pm\" etc.\n",
    "Note that the data was saved in UTC time. Our data falls in April of 2010 which occurred during Daylight Savings Time in New York. For that reason, we'll make an adjustment to EDT using UTC-4 (subtracting four hours)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>fare_class</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>dist_km</th>\n",
       "      <th>EDTdate</th>\n",
       "      <th>Hour</th>\n",
       "      <th>AMorPM</th>\n",
       "      <th>Weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-04-19 08:17:56 UTC</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.992365</td>\n",
       "      <td>40.730521</td>\n",
       "      <td>-73.975499</td>\n",
       "      <td>40.744746</td>\n",
       "      <td>1</td>\n",
       "      <td>2.126312</td>\n",
       "      <td>2010-04-19 04:17:56</td>\n",
       "      <td>4</td>\n",
       "      <td>am</td>\n",
       "      <td>Mon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-04-17 15:43:53 UTC</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.990078</td>\n",
       "      <td>40.740558</td>\n",
       "      <td>-73.974232</td>\n",
       "      <td>40.744114</td>\n",
       "      <td>1</td>\n",
       "      <td>1.392307</td>\n",
       "      <td>2010-04-17 11:43:53</td>\n",
       "      <td>11</td>\n",
       "      <td>am</td>\n",
       "      <td>Sat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-04-17 11:23:26 UTC</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.994149</td>\n",
       "      <td>40.751118</td>\n",
       "      <td>-73.960064</td>\n",
       "      <td>40.766235</td>\n",
       "      <td>2</td>\n",
       "      <td>3.326763</td>\n",
       "      <td>2010-04-17 07:23:26</td>\n",
       "      <td>7</td>\n",
       "      <td>am</td>\n",
       "      <td>Sat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-04-11 21:25:03 UTC</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.990485</td>\n",
       "      <td>40.756422</td>\n",
       "      <td>-73.971205</td>\n",
       "      <td>40.748192</td>\n",
       "      <td>1</td>\n",
       "      <td>1.864129</td>\n",
       "      <td>2010-04-11 17:25:03</td>\n",
       "      <td>17</td>\n",
       "      <td>pm</td>\n",
       "      <td>Sun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-04-17 02:19:01 UTC</td>\n",
       "      <td>19.7</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.990976</td>\n",
       "      <td>40.734202</td>\n",
       "      <td>-73.905956</td>\n",
       "      <td>40.743115</td>\n",
       "      <td>1</td>\n",
       "      <td>7.231321</td>\n",
       "      <td>2010-04-16 22:19:01</td>\n",
       "      <td>22</td>\n",
       "      <td>pm</td>\n",
       "      <td>Fri</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pickup_datetime  fare_amount  fare_class  pickup_longitude  \\\n",
       "0  2010-04-19 08:17:56 UTC          6.5           0        -73.992365   \n",
       "1  2010-04-17 15:43:53 UTC          6.9           0        -73.990078   \n",
       "2  2010-04-17 11:23:26 UTC         10.1           1        -73.994149   \n",
       "3  2010-04-11 21:25:03 UTC          8.9           0        -73.990485   \n",
       "4  2010-04-17 02:19:01 UTC         19.7           1        -73.990976   \n",
       "\n",
       "   pickup_latitude  dropoff_longitude  dropoff_latitude  passenger_count  \\\n",
       "0        40.730521         -73.975499         40.744746                1   \n",
       "1        40.740558         -73.974232         40.744114                1   \n",
       "2        40.751118         -73.960064         40.766235                2   \n",
       "3        40.756422         -73.971205         40.748192                1   \n",
       "4        40.734202         -73.905956         40.743115                1   \n",
       "\n",
       "    dist_km             EDTdate  Hour AMorPM Weekday  \n",
       "0  2.126312 2010-04-19 04:17:56     4     am     Mon  \n",
       "1  1.392307 2010-04-17 11:43:53    11     am     Sat  \n",
       "2  3.326763 2010-04-17 07:23:26     7     am     Sat  \n",
       "3  1.864129 2010-04-11 17:25:03    17     pm     Sun  \n",
       "4  7.231321 2010-04-16 22:19:01    22     pm     Fri  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['EDTdate'] = pd.to_datetime(df['pickup_datetime'].str[:19]) - pd.Timedelta(hours=4)\n",
    "df['Hour'] = df['EDTdate'].dt.hour\n",
    "df['AMorPM'] = np.where(df['Hour']<12,'am','pm')\n",
    "df['Weekday'] = df['EDTdate'].dt.strftime(\"%a\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2010-04-11 00:00:10')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['EDTdate'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2010-04-24 23:59:42')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['EDTdate'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate categorical from continuous columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pickup_datetime', 'fare_amount', 'fare_class', 'pickup_longitude',\n",
       "       'pickup_latitude', 'dropoff_longitude', 'dropoff_latitude',\n",
       "       'passenger_count', 'dist_km', 'EDTdate', 'Hour', 'AMorPM', 'Weekday'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here I wanted to through the problem as a Regression Problem, so I picked the \"Fare_amount\" for labels, Later for Classification problem I choose the \"Fare_class\" column.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['Hour', 'AMorPM', 'Weekday']\n",
    "cont_cols = ['pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude', 'passenger_count', 'dist_km']\n",
    "y_col = ['fare_amount']  # this column contains the labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorify\n",
    "\n",
    "\n",
    "Pandas offers a <a href='https://pandas.pydata.org/pandas-docs/stable/user_guide/categorical.html'><strong>category dtype</strong></a> for converting categorical values to numerical codes. A dataset containing months of the year will be assigned 12 codes, one for each month. These will usually be the integers 0 to 11. Pandas replaces the column values with codes, and retains an index list of category values. In the steps ahead I'll call the categorical values \"names\" and the encodings \"codes\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert our three categorical columns to category dtypes.\n",
    "for cat in cat_cols:\n",
    "    df[cat] = df[cat].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pickup_datetime              object\n",
       "fare_amount                 float64\n",
       "fare_class                    int64\n",
       "pickup_longitude            float64\n",
       "pickup_latitude             float64\n",
       "dropoff_longitude           float64\n",
       "dropoff_latitude            float64\n",
       "passenger_count               int64\n",
       "dist_km                     float64\n",
       "EDTdate              datetime64[ns]\n",
       "Hour                       category\n",
       "AMorPM                     category\n",
       "Weekday                    category\n",
       "dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     4\n",
       "1    11\n",
       "2     7\n",
       "3    17\n",
       "4    22\n",
       "Name: Hour, dtype: category\n",
       "Categories (24, int64): [0, 1, 2, 3, ..., 20, 21, 22, 23]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Hour'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here our categorical names are the integers 0 through 23, for a total of 24 unique categories. These values <em>also</em> correspond to the codes assigned to each name.\n",
    "\n",
    "We can access the category names with <tt>Series.cat.categories</tt> or just the codes with <tt>Series.cat.codes</tt>. This will make more sense if we look at <tt>df['AMorPM']</tt>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['am', 'pm'], dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['AMorPM'].cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    1\n",
       "4    1\n",
       "dtype: int8"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['AMorPM'].head().cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4,  0,  1],\n",
       "       [11,  0,  2],\n",
       "       [ 7,  0,  2],\n",
       "       [17,  1,  3],\n",
       "       [22,  1,  0]], dtype=int8)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hr = df['Hour'].cat.codes.values\n",
    "ampm = df['AMorPM'].cat.codes.values\n",
    "wkdy = df['Weekday'].cat.codes.values\n",
    "\n",
    "cats = np.stack([hr, ampm, wkdy], 1)\n",
    "\n",
    "cats[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert numpy arrays to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4,  0,  1],\n",
       "        [11,  0,  2],\n",
       "        [ 7,  0,  2],\n",
       "        [17,  1,  3],\n",
       "        [22,  1,  0]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert categorical variables to a tensor\n",
    "cats = torch.tensor(cats, dtype=torch.int64) \n",
    "# this syntax is ok, since the source data is an array, not an existing tensor\n",
    "\n",
    "cats[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 40.7305, -73.9924,  40.7447, -73.9755,   1.0000,   2.1263],\n",
       "        [ 40.7406, -73.9901,  40.7441, -73.9742,   1.0000,   1.3923],\n",
       "        [ 40.7511, -73.9941,  40.7662, -73.9601,   2.0000,   3.3268],\n",
       "        [ 40.7564, -73.9905,  40.7482, -73.9712,   1.0000,   1.8641],\n",
       "        [ 40.7342, -73.9910,  40.7431, -73.9060,   1.0000,   7.2313]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert continuous variables to a tensor\n",
    "conts = np.stack([df[col].values for col in cont_cols], 1)\n",
    "conts = torch.tensor(conts, dtype=torch.float)\n",
    "conts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.5000],\n",
       "        [ 6.9000],\n",
       "        [10.1000],\n",
       "        [ 8.9000],\n",
       "        [19.7000]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert labels to a tensor\n",
    "y = torch.tensor(df[y_col].values, dtype=torch.float).reshape(-1,1)\n",
    "\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120000, 3])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120000, 6])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120000, 1])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set an embedding size\n",
    "\n",
    "The rule of thumb for determining the embedding size is to divide the number of unique entries in each column by 2, but not to exceed 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(24, 12), (2, 1), (7, 4)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This will set embedding sizes for Hours, AMvsPM and Weekdays\n",
    "cat_szs = [len(df[col].cat.categories) for col in cat_cols]\n",
    "emb_szs = [(size, min(50, (size+1)//2)) for size in cat_szs]\n",
    "emb_szs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a TabularModel\n",
    "\n",
    "\n",
    "This somewhat follows the <a href='https://docs.fast.ai/tabular.models.html'>fast.ai library</a> The goal is to define a model based on the number of continuous columns (given by <tt>conts.shape[1]</tt>) plus the number of categorical columns and their embeddings (given by <tt>len(emb_szs)</tt> and <tt>emb_szs</tt> respectively). The output would either be a regression (a single float value), or a classification (a group of bins and their softmax values). For this exercise our output will be a single regression value. Note that we'll assume our data contains both categorical and continuous data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><strong>Let's walk through the steps we're about to take. \n",
    "    \n",
    "    \n",
    "1. Extend the base Module class, set up the following parameters:\n",
    "   * <tt>emb_szs: </tt>list of tuples: each categorical variable size is paired with an embedding size\n",
    "   * <tt>n_cont:  </tt>int: number of continuous variables\n",
    "   * <tt>out_sz:  </tt>int: output size\n",
    "   * <tt>layers:  </tt>list of ints: layer sizes\n",
    "   * <tt>p:       </tt>float: dropout probability for each layer (for simplicity we'll use the same value throughout)\n",
    "   \n",
    "<tt><font color=black>class TabularModel(nn.Module):<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;def \\_\\_init\\_\\_(self, emb_szs, n_cont, out_sz, layers, p=0.5):<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;super().\\_\\_init\\_\\_()</font></tt><br>\n",
    "\n",
    "2. Set up the embedded layers with <a href='https://pytorch.org/docs/stable/nn.html#modulelist'><tt><strong>torch.nn.ModuleList()</strong></tt></a> and <a href='https://pytorch.org/docs/stable/nn.html#embedding'><tt><strong>torch.nn.Embedding()</strong></tt></a><br>Categorical data will be filtered through these Embeddings in the forward section.<br>\n",
    "<tt><font color=black>&nbsp;&nbsp;&nbsp;&nbsp;self.embeds = nn.ModuleList([nn.Embedding(ni, nf) for ni,nf in emb_szs])</font></tt><br><br>\n",
    "3. Set up a dropout function for the embeddings with <a href='https://pytorch.org/docs/stable/nn.html#dropout'><tt><strong>torch.nn.Dropout()</strong></tt></a> The default p-value=0.5<br>\n",
    "<tt><font color=black>&nbsp;&nbsp;&nbsp;&nbsp;self.emb_drop = nn.Dropout(emb_drop)</font></tt><br><br>\n",
    "4. Set up a normalization function for the continuous variables with <a href='https://pytorch.org/docs/stable/nn.html#batchnorm1d'><tt><strong>torch.nn.BatchNorm1d()</strong></tt></a><br>\n",
    "<tt><font color=black>&nbsp;&nbsp;&nbsp;&nbsp;self.bn_cont = nn.BatchNorm1d(n_cont)</font></tt><br><br>\n",
    "5. Set up a sequence of neural network layers where each level includes a Linear function, an activation function (we'll use <a href='https://pytorch.org/docs/stable/nn.html#relu'><strong>ReLU</strong></a>), a normalization step, and a dropout layer. We'll combine the list of layers with <a href='https://pytorch.org/docs/stable/nn.html#sequential'><tt><strong>torch.nn.Sequential()</strong></tt></a><br>\n",
    "<tt><font color=black>&nbsp;&nbsp;&nbsp;&nbsp;self.bn_cont = nn.BatchNorm1d(n_cont)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;layerlist = []<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;n_emb = sum((nf for ni,nf in emb_szs))<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;n_in = n_emb + n_cont<br>\n",
    "<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;for i in layers:<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;layerlist.append(nn.Linear(n_in,i)) <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;layerlist.append(nn.ReLU(inplace=True))<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;layerlist.append(nn.BatchNorm1d(i))<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;layerlist.append(nn.Dropout(p))<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;n_in = i<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;layerlist.append(nn.Linear(layers[-1],out_sz))<br>\n",
    "<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;self.layers = nn.Sequential(*layerlist)</font></tt><br><br>\n",
    "6. Define the forward method. Preprocess the embeddings and normalize the continuous variables before passing them through the layers.<br>Use <a href='https://pytorch.org/docs/stable/torch.html#torch.cat'><tt><strong>torch.cat()</strong></tt></a> to combine multiple tensors into one.<br>\n",
    "<tt><font color=black>&nbsp;&nbsp;&nbsp;&nbsp;def forward(self, x_cat, x_cont):<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;embeddings = []<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;for i,e in enumerate(self.embeds):<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;embeddings.append(e(x_cat[:,i]))<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;x = torch.cat(embeddings, 1)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;x = self.emb_drop(x)<br>\n",
    "<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;x_cont = self.bn_cont(x_cont)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;x = torch.cat([x, x_cont], 1)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;x = self.layers(x)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;return x</font></tt>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4,  0,  1],\n",
       "        [11,  0,  2],\n",
       "        [ 7,  0,  2],\n",
       "        [17,  1,  3]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is our source data\n",
    "catz = cats[:4]\n",
    "catz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(24, 12), (2, 1), (7, 4)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is passed in when the model is instantiated\n",
    "emb_szs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Embedding(24, 12)\n",
       "  (1): Embedding(2, 1)\n",
       "  (2): Embedding(7, 4)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is assigned inside the __init__() method\n",
    "selfembeds = nn.ModuleList([nn.Embedding(ni, nf) for ni,nf in emb_szs])\n",
    "selfembeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, Embedding(24, 12)), (1, Embedding(2, 1)), (2, Embedding(7, 4))]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(enumerate(selfembeds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-0.4894,  0.4585,  1.2695,  0.3104,  0.1320,  0.4403,  1.0644, -0.0136,\n",
       "          -0.5477,  0.9099, -0.2839, -0.2834],\n",
       "         [-0.3099, -0.2069, -0.3287,  2.4141,  0.6512, -0.9431, -1.1507,  0.1587,\n",
       "           0.0155,  0.3611, -0.0857, -0.3819],\n",
       "         [ 0.5152,  1.0557, -1.0856, -0.4845,  0.9278, -0.3767, -1.7051, -0.4047,\n",
       "           0.5953,  2.0438, -1.3665,  1.5119],\n",
       "         [ 0.3942, -0.2879,  0.0057,  1.5277,  1.2815, -2.8780, -0.0300,  0.0425,\n",
       "           0.4049,  1.0810, -0.4833,  0.9273]], grad_fn=<EmbeddingBackward>),\n",
       " tensor([[-0.2050],\n",
       "         [-0.2050],\n",
       "         [-0.2050],\n",
       "         [ 1.0401]], grad_fn=<EmbeddingBackward>),\n",
       " tensor([[ 1.1040,  0.6536, -1.6993, -0.0250],\n",
       "         [-2.1238,  0.8824,  0.1988,  1.8035],\n",
       "         [-2.1238,  0.8824,  0.1988,  1.8035],\n",
       "         [-1.7024, -2.1447, -0.7593,  1.0203]], grad_fn=<EmbeddingBackward>)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This happens inside the forward() method\n",
    "embeddingz = []\n",
    "for i,e in enumerate(selfembeds):\n",
    "    embeddingz.append(e(catz[:,i]))\n",
    "embeddingz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4894,  0.4585,  1.2695,  0.3104,  0.1320,  0.4403,  1.0644, -0.0136,\n",
       "         -0.5477,  0.9099, -0.2839, -0.2834, -0.2050,  1.1040,  0.6536, -1.6993,\n",
       "         -0.0250],\n",
       "        [-0.3099, -0.2069, -0.3287,  2.4141,  0.6512, -0.9431, -1.1507,  0.1587,\n",
       "          0.0155,  0.3611, -0.0857, -0.3819, -0.2050, -2.1238,  0.8824,  0.1988,\n",
       "          1.8035],\n",
       "        [ 0.5152,  1.0557, -1.0856, -0.4845,  0.9278, -0.3767, -1.7051, -0.4047,\n",
       "          0.5953,  2.0438, -1.3665,  1.5119, -0.2050, -2.1238,  0.8824,  0.1988,\n",
       "          1.8035],\n",
       "        [ 0.3942, -0.2879,  0.0057,  1.5277,  1.2815, -2.8780, -0.0300,  0.0425,\n",
       "          0.4049,  1.0810, -0.4833,  0.9273,  1.0401, -1.7024, -2.1447, -0.7593,\n",
       "          1.0203]], grad_fn=<CatBackward>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenate the embedding sections (12,1,4) into one (17)\n",
    "z = torch.cat(embeddingz, 1)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This was assigned under the __init__() method\n",
    "selfembdrop = nn.Dropout(.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8156,  0.7641,  2.1158,  0.0000,  0.2200,  0.7338,  1.7741, -0.0227,\n",
       "         -0.9128,  1.5165, -0.4732, -0.4723, -0.3416,  1.8399,  0.0000, -0.0000,\n",
       "         -0.0417],\n",
       "        [-0.0000, -0.3448, -0.5478,  4.0236,  0.0000, -0.0000, -1.9178,  0.0000,\n",
       "          0.0258,  0.6018, -0.0000, -0.0000, -0.0000, -0.0000,  1.4706,  0.3313,\n",
       "          3.0059],\n",
       "        [ 0.0000,  1.7595, -0.0000, -0.8075,  0.0000, -0.6278, -2.8418, -0.6746,\n",
       "          0.9922,  3.4063, -0.0000,  0.0000, -0.3416, -3.5397,  0.0000,  0.0000,\n",
       "          3.0059],\n",
       "        [ 0.0000, -0.4798,  0.0095,  2.5461,  2.1359, -4.7967, -0.0000,  0.0000,\n",
       "          0.6749,  0.0000, -0.0000,  0.0000,  1.7335, -2.8374, -3.5746, -1.2655,\n",
       "          1.7005]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = selfembdrop(z)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularModel(nn.Module):\n",
    "\n",
    "    def __init__(self, emb_szs, n_cont, out_sz, layers, p=0.5):\n",
    "        super().__init__()\n",
    "        self.embeds = nn.ModuleList([nn.Embedding(ni, nf) for ni,nf in emb_szs])\n",
    "        self.emb_drop = nn.Dropout(p)\n",
    "        self.bn_cont = nn.BatchNorm1d(n_cont)\n",
    "        \n",
    "        layerlist = []\n",
    "        n_emb = sum((nf for ni,nf in emb_szs))\n",
    "        n_in = n_emb + n_cont\n",
    "        \n",
    "        for i in layers:\n",
    "            layerlist.append(nn.Linear(n_in,i)) \n",
    "            layerlist.append(nn.ReLU(inplace=True))\n",
    "            layerlist.append(nn.BatchNorm1d(i))\n",
    "            layerlist.append(nn.Dropout(p))\n",
    "            n_in = i\n",
    "        layerlist.append(nn.Linear(layers[-1],out_sz))\n",
    "            \n",
    "        self.layers = nn.Sequential(*layerlist)\n",
    "    \n",
    "    def forward(self, x_cat, x_cont):\n",
    "        embeddings = []\n",
    "        for i,e in enumerate(self.embeds):\n",
    "            embeddings.append(e(x_cat[:,i]))\n",
    "        x = torch.cat(embeddings, 1)\n",
    "        x = self.emb_drop(x)\n",
    "        \n",
    "        x_cont = self.bn_cont(x_cont)\n",
    "        x = torch.cat([x, x_cont], 1)\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(33)\n",
    "model = TabularModel(emb_szs, conts.shape[1], 1, [200,100], p=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TabularModel(\n",
       "  (embeds): ModuleList(\n",
       "    (0): Embedding(24, 12)\n",
       "    (1): Embedding(2, 1)\n",
       "    (2): Embedding(7, 4)\n",
       "  )\n",
       "  (emb_drop): Dropout(p=0.4)\n",
       "  (bn_cont): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=23, out_features=200, bias=True)\n",
       "    (1): ReLU(inplace)\n",
       "    (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.4)\n",
       "    (4): Linear(in_features=200, out_features=100, bias=True)\n",
       "    (5): ReLU(inplace)\n",
       "    (6): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Dropout(p=0.4)\n",
       "    (8): Linear(in_features=100, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define loss function & optimizer\n",
    "\n",
    "\n",
    "PyTorch does not offer a built-in <a href='https://en.wikipedia.org/wiki/Root-mean-square_deviation'>RMSE Loss</a> function, and it would be nice to see this in place of MSE.<br>\n",
    "For this reason, I'll simply apply the <tt>torch.sqrt()</tt> function to the output of MSELoss during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()  # we'll convert this to RMSE later\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform train/test splits\n",
    "\n",
    "At this point my batch size is the entire dataset of 120,000 records. This will take a long time to train. I'll use 60,000. Recall that my tensors are already randomly shuffled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 60000\n",
    "test_size = int(batch_size * .2)\n",
    "\n",
    "cat_train = cats[:batch_size-test_size]\n",
    "cat_test = cats[batch_size-test_size:batch_size]\n",
    "con_train = conts[:batch_size-test_size]\n",
    "con_test = conts[batch_size-test_size:batch_size]\n",
    "y_train = y[:batch_size-test_size]\n",
    "y_test = y[batch_size-test_size:batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   1  loss: 12.49953079\n",
      "epoch:  26  loss: 11.52666759\n",
      "epoch:  51  loss: 10.47162533\n",
      "epoch:  76  loss: 9.53090382\n",
      "epoch: 101  loss: 8.72838020\n",
      "epoch: 126  loss: 7.81538534\n",
      "epoch: 151  loss: 6.70782852\n",
      "epoch: 176  loss: 5.48520994\n",
      "epoch: 201  loss: 4.37029028\n",
      "epoch: 226  loss: 3.70538783\n",
      "epoch: 251  loss: 3.51656818\n",
      "epoch: 276  loss: 3.44707990\n",
      "epoch: 300  loss: 3.42467499\n",
      "\n",
      "Duration: 896 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "epochs = 300\n",
    "losses = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    i+=1\n",
    "    y_pred = model(cat_train, con_train)\n",
    "    loss = torch.sqrt(criterion(y_pred, y_train)) # RMSE\n",
    "    losses.append(loss)\n",
    "    \n",
    "    # a neat trick to save screen space:\n",
    "    if i%25 == 1:\n",
    "        print(f'epoch: {i:3}  loss: {loss.item():10.8f}')\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(f'epoch: {i:3}  loss: {loss.item():10.8f}') # print the last line\n",
    "print(f'\\nDuration: {time.time() - start_time:.0f} seconds') # print the time elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(epochs), losses)\n",
    "plt.ylabel('RMSE Loss')\n",
    "plt.xlabel('epoch');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate the model\n",
    "\n",
    "\n",
    "Here I want to run the entire test set through the model, and compare it to the known labels.<br>\n",
    "For this step I don't want to update weights and biases, so I set <tt>torch.no_grad()</tt>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 3.34590030\n"
     ]
    }
   ],
   "source": [
    "# TO EVALUATE THE ENTIRE TEST SET\n",
    "with torch.no_grad():\n",
    "    y_val = model(cat_test, con_test)\n",
    "    loss = torch.sqrt(criterion(y_val, y_test))\n",
    "print(f'RMSE: {loss:.8f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that on average, predicted values are within &plusmn;$3.31 of the actual value.\n",
    "\n",
    "Now let's look at the first 50 predicted values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PREDICTED   ACTUAL     DIFF\n",
      " 1.   2.5379   2.9000   0.3621\n",
      " 2.  25.1634   5.7000  19.4634\n",
      " 3.   6.3749   7.7000   1.3251\n",
      " 4.  13.4677  12.5000   0.9677\n",
      " 5.   4.4992   4.1000   0.3992\n",
      " 6.   4.8968   5.3000   0.4032\n",
      " 7.   3.1796   3.7000   0.5204\n",
      " 8.  17.7814  14.5000   3.2814\n",
      " 9.   6.1348   5.7000   0.4348\n",
      "10.  12.0325  10.1000   1.9325\n",
      "11.   6.1323   4.5000   1.6323\n",
      "12.   6.9208   6.1000   0.8208\n",
      "13.   5.9448   6.9000   0.9552\n",
      "14.  13.4625  14.1000   0.6375\n",
      "15.   5.9277   4.5000   1.4277\n",
      "16.  27.5778  34.1000   6.5222\n",
      "17.   3.2774  12.5000   9.2226\n",
      "18.   5.7506   4.1000   1.6506\n",
      "19.   8.1940   8.5000   0.3060\n",
      "20.   6.2858   5.3000   0.9858\n",
      "21.  13.6693  11.3000   2.3693\n",
      "22.   9.6759  10.5000   0.8241\n",
      "23.  16.0568  15.3000   0.7568\n",
      "24.  19.3310  14.9000   4.4310\n",
      "25.  48.6873  49.5700   0.8827\n",
      "26.   6.3257   5.3000   1.0257\n",
      "27.   6.0392   3.7000   2.3392\n",
      "28.   7.1921   6.5000   0.6921\n",
      "29.  14.9567  14.1000   0.8567\n",
      "30.   6.7476   4.9000   1.8476\n",
      "31.   4.3447   3.7000   0.6447\n",
      "32.  35.6969  38.6700   2.9731\n",
      "33.  13.9892  12.5000   1.4892\n",
      "34.  12.8934  16.5000   3.6066\n",
      "35.   6.3164   5.7000   0.6164\n",
      "36.   5.9684   8.9000   2.9316\n",
      "37.  16.1289  22.1000   5.9711\n",
      "38.   7.6541  12.1000   4.4459\n",
      "39.   8.6153  10.1000   1.4847\n",
      "40.   4.0447   3.3000   0.7447\n",
      "41.  10.2168   8.5000   1.7168\n",
      "42.   8.8325   8.1000   0.7325\n",
      "43.  15.2500  14.5000   0.7500\n",
      "44.   6.3571   4.9000   1.4571\n",
      "45.   9.7002   8.5000   1.2002\n",
      "46.  12.1134  12.1000   0.0134\n",
      "47.  24.3001  23.7000   0.6001\n",
      "48.   2.8357   3.7000   0.8643\n",
      "49.   6.8266   9.3000   2.4734\n",
      "50.   8.2082   8.1000   0.1082\n"
     ]
    }
   ],
   "source": [
    "print(f'{\"PREDICTED\":>12} {\"ACTUAL\":>8} {\"DIFF\":>8}')\n",
    "for i in range(50):\n",
    "    diff = np.abs(y_val[i].item()-y_test[i].item())\n",
    "    print(f'{i+1:2}. {y_val[i].item():8.4f} {y_test[i].item():8.4f} {diff:8.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure to save the model only after the training has happened!\n",
    "if len(losses) == epochs:\n",
    "    torch.save(model.state_dict(), 'TaxiFareRegrModel.pt')\n",
    "else:\n",
    "    print('Model has not been trained. Consider loading a trained model instead.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a saved model (starting from scratch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def haversine_distance(df, lat1, long1, lat2, long2):\n",
    "    r = 6371\n",
    "    phi1 = np.radians(df[lat1])\n",
    "    phi2 = np.radians(df[lat2])\n",
    "    delta_phi = np.radians(df[lat2]-df[lat1])\n",
    "    delta_lambda = np.radians(df[long2]-df[long1])\n",
    "    a = np.sin(delta_phi/2)**2 + np.cos(phi1) * np.cos(phi2) * np.sin(delta_lambda/2)**2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n",
    "    return r * c\n",
    "\n",
    "class TabularModel(nn.Module):\n",
    "    def __init__(self, emb_szs, n_cont, out_sz, layers, p=0.5):\n",
    "        super().__init__()\n",
    "        self.embeds = nn.ModuleList([nn.Embedding(ni, nf) for ni,nf in emb_szs])\n",
    "        self.emb_drop = nn.Dropout(p)\n",
    "        self.bn_cont = nn.BatchNorm1d(n_cont)\n",
    "        layerlist = []\n",
    "        n_emb = sum((nf for ni,nf in emb_szs))\n",
    "        n_in = n_emb + n_cont\n",
    "        for i in layers:\n",
    "            layerlist.append(nn.Linear(n_in,i)) \n",
    "            layerlist.append(nn.ReLU(inplace=True))\n",
    "            layerlist.append(nn.BatchNorm1d(i))\n",
    "            layerlist.append(nn.Dropout(p))\n",
    "            n_in = i\n",
    "        layerlist.append(nn.Linear(layers[-1],out_sz))\n",
    "        self.layers = nn.Sequential(*layerlist)\n",
    "    def forward(self, x_cat, x_cont):\n",
    "        embeddings = []\n",
    "        for i,e in enumerate(self.embeds):\n",
    "            embeddings.append(e(x_cat[:,i]))\n",
    "        x = torch.cat(embeddings, 1)\n",
    "        x = self.emb_drop(x)\n",
    "        x_cont = self.bn_cont(x_cont)\n",
    "        x = torch.cat([x, x_cont], 1)\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_szs = [(24, 12), (2, 1), (7, 4)]\n",
    "model2 = TabularModel(emb_szs, 6, 1, [200,100], p=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TabularModel(\n",
       "  (embeds): ModuleList(\n",
       "    (0): Embedding(24, 12)\n",
       "    (1): Embedding(2, 1)\n",
       "    (2): Embedding(7, 4)\n",
       "  )\n",
       "  (emb_drop): Dropout(p=0.4)\n",
       "  (bn_cont): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=23, out_features=200, bias=True)\n",
       "    (1): ReLU(inplace)\n",
       "    (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.4)\n",
       "    (4): Linear(in_features=200, out_features=100, bias=True)\n",
       "    (5): ReLU(inplace)\n",
       "    (6): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Dropout(p=0.4)\n",
       "    (8): Linear(in_features=100, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.load_state_dict(torch.load('TaxiFareRegrModel.pt'));\n",
    "model2.eval() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_data(mdl): # pass in the name of the new model\n",
    "    # INPUT NEW DATA\n",
    "    plat = float(input('What is the pickup latitude?  '))\n",
    "    plong = float(input('What is the pickup longitude? '))\n",
    "    dlat = float(input('What is the dropoff latitude?  '))\n",
    "    dlong = float(input('What is the dropoff longitude? '))\n",
    "    psngr = int(input('How many passengers? '))\n",
    "    dt = input('What is the pickup date and time?\\nFormat as YYYY-MM-DD HH:MM:SS     ')\n",
    "    \n",
    "    # PREPROCESS THE DATA\n",
    "    dfx_dict = {'pickup_latitude':plat,'pickup_longitude':plong,'dropoff_latitude':dlat,\n",
    "         'dropoff_longitude':dlong,'passenger_count':psngr,'EDTdate':dt}\n",
    "    dfx = pd.DataFrame(dfx_dict, index=[0])\n",
    "    dfx['dist_km'] = haversine_distance(dfx,'pickup_latitude', 'pickup_longitude',\n",
    "                                        'dropoff_latitude', 'dropoff_longitude')\n",
    "    dfx['EDTdate'] = pd.to_datetime(dfx['EDTdate'])\n",
    "    \n",
    "    # We can skip the .astype(category) step since our fields are small,\n",
    "    # and encode them right away\n",
    "    dfx['Hour'] = dfx['EDTdate'].dt.hour\n",
    "    dfx['AMorPM'] = np.where(dfx['Hour']<12,0,1) \n",
    "    dfx['Weekday'] = dfx['EDTdate'].dt.strftime(\"%a\")\n",
    "    dfx['Weekday'] = dfx['Weekday'].replace(['Fri','Mon','Sat','Sun','Thu','Tue','Wed'],\n",
    "                                            [0,1,2,3,4,5,6]).astype('int64')\n",
    "    # CREATE CAT AND CONT TENSORS\n",
    "    cat_cols = ['Hour', 'AMorPM', 'Weekday']\n",
    "    cont_cols = ['pickup_latitude', 'pickup_longitude', 'dropoff_latitude',\n",
    "                 'dropoff_longitude', 'passenger_count', 'dist_km']\n",
    "    xcats = np.stack([dfx[col].values for col in cat_cols], 1)\n",
    "    xcats = torch.tensor(xcats, dtype=torch.int64)\n",
    "    xconts = np.stack([dfx[col].values for col in cont_cols], 1)\n",
    "    xconts = torch.tensor(xconts, dtype=torch.float)\n",
    "    \n",
    "    # PASS NEW DATA THROUGH THE MODEL WITHOUT PERFORMING A BACKPROP\n",
    "    with torch.no_grad():\n",
    "        z = mdl(xcats, xconts)\n",
    "    print(f'\\nThe predicted fare amount is ${z.item():.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed new data through the trained model\n",
    "\n",
    "\n",
    "For convenience, here are the max and min values for each of the variables:\n",
    "<table style=\"display: inline-block\">\n",
    "<tr><th>Column</th><th>Minimum</th><th>Maximum</th></tr>\n",
    "<tr><td>pickup_latitude</td><td>40</td><td>41</td></tr>\n",
    "<tr><td>pickup_longitude</td><td>-74.5</td><td>-73.3</td></tr>\n",
    "<tr><td>dropoff_latitude</td><td>40</td><td>41</td></tr>\n",
    "<tr><td>dropoff_longitude</td><td>-74.5</td><td>-73.3</td></tr>\n",
    "<tr><td>passenger_count</td><td>1</td><td>5</td></tr>\n",
    "<tr><td>EDTdate</td><td>2010-04-11 00:00:00</td><td>2010-04-24 23:59:42</td></tr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Use caution!</strong> The distance between 1 degree of latitude (from 40 to 41) is 111km (69mi) and between 1 degree of longitude (from -73 to -74) is 85km (53mi). The longest cab ride in the dataset spanned a difference of only 0.243 degrees latitude and 0.284 degrees longitude. The mean difference for both latitude and longitude was about 0.02. To get a fair prediction, use values that fall close to one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the pickup latitude?  40.5\n",
      "What is the pickup longitude? -73.9\n",
      "What is the dropoff latitude?  40.52\n",
      "What is the dropoff longitude? -73.92\n",
      "How many passengers? 2\n",
      "What is the pickup date and time?\n",
      "Format as YYYY-MM-DD HH:MM:SS     2010-04-15 16:00:00\n",
      "\n",
      "The predicted fare amount is $13.86\n"
     ]
    }
   ],
   "source": [
    "z = test_data(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Network - CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>fare_class</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-04-19 08:17:56 UTC</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.992365</td>\n",
       "      <td>40.730521</td>\n",
       "      <td>-73.975499</td>\n",
       "      <td>40.744746</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-04-17 15:43:53 UTC</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.990078</td>\n",
       "      <td>40.740558</td>\n",
       "      <td>-73.974232</td>\n",
       "      <td>40.744114</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-04-17 11:23:26 UTC</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.994149</td>\n",
       "      <td>40.751118</td>\n",
       "      <td>-73.960064</td>\n",
       "      <td>40.766235</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-04-11 21:25:03 UTC</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.990485</td>\n",
       "      <td>40.756422</td>\n",
       "      <td>-73.971205</td>\n",
       "      <td>40.748192</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-04-17 02:19:01 UTC</td>\n",
       "      <td>19.7</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.990976</td>\n",
       "      <td>40.734202</td>\n",
       "      <td>-73.905956</td>\n",
       "      <td>40.743115</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pickup_datetime  fare_amount  fare_class  pickup_longitude  \\\n",
       "0  2010-04-19 08:17:56 UTC          6.5           0        -73.992365   \n",
       "1  2010-04-17 15:43:53 UTC          6.9           0        -73.990078   \n",
       "2  2010-04-17 11:23:26 UTC         10.1           1        -73.994149   \n",
       "3  2010-04-11 21:25:03 UTC          8.9           0        -73.990485   \n",
       "4  2010-04-17 02:19:01 UTC         19.7           1        -73.990976   \n",
       "\n",
       "   pickup_latitude  dropoff_longitude  dropoff_latitude  passenger_count  \n",
       "0        40.730521         -73.975499         40.744746                1  \n",
       "1        40.740558         -73.974232         40.744114                1  \n",
       "2        40.751118         -73.960064         40.766235                2  \n",
       "3        40.756422         -73.971205         40.748192                1  \n",
       "4        40.734202         -73.905956         40.743115                1  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../Data/NYCTaxiFares.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    80000\n",
       "1    40000\n",
       "Name: fare_class, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['fare_class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conveniently, 2/3 of the data have fares under \\\\$10, and 1/3 have fares \\\\$10 and above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fare classes correspond to fare amounts as follows:\n",
    "<table style=\"display: inline-block\">\n",
    "<tr><th>Class</th><th>Values</th></tr>\n",
    "<tr><td>0</td><td>< \\$10.00</td></tr>\n",
    "<tr><td>1</td><td>>= \\$10.00</td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_distance(df, lat1, long1, lat2, long2):\n",
    "    \"\"\"\n",
    "    Calculates the haversine distance between 2 sets of GPS coordinates in df\n",
    "    \"\"\"\n",
    "    r = 6371  # average radius of Earth in kilometers\n",
    "       \n",
    "    phi1 = np.radians(df[lat1])\n",
    "    phi2 = np.radians(df[lat2])\n",
    "    \n",
    "    delta_phi = np.radians(df[lat2]-df[lat1])\n",
    "    delta_lambda = np.radians(df[long2]-df[long1])\n",
    "     \n",
    "    a = np.sin(delta_phi/2)**2 + np.cos(phi1) * np.cos(phi2) * np.sin(delta_lambda/2)**2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n",
    "    d = (r * c) # in kilometers\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>fare_class</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>dist_km</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-04-19 08:17:56 UTC</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.992365</td>\n",
       "      <td>40.730521</td>\n",
       "      <td>-73.975499</td>\n",
       "      <td>40.744746</td>\n",
       "      <td>1</td>\n",
       "      <td>2.126312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-04-17 15:43:53 UTC</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.990078</td>\n",
       "      <td>40.740558</td>\n",
       "      <td>-73.974232</td>\n",
       "      <td>40.744114</td>\n",
       "      <td>1</td>\n",
       "      <td>1.392307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-04-17 11:23:26 UTC</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.994149</td>\n",
       "      <td>40.751118</td>\n",
       "      <td>-73.960064</td>\n",
       "      <td>40.766235</td>\n",
       "      <td>2</td>\n",
       "      <td>3.326763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-04-11 21:25:03 UTC</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.990485</td>\n",
       "      <td>40.756422</td>\n",
       "      <td>-73.971205</td>\n",
       "      <td>40.748192</td>\n",
       "      <td>1</td>\n",
       "      <td>1.864129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-04-17 02:19:01 UTC</td>\n",
       "      <td>19.7</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.990976</td>\n",
       "      <td>40.734202</td>\n",
       "      <td>-73.905956</td>\n",
       "      <td>40.743115</td>\n",
       "      <td>1</td>\n",
       "      <td>7.231321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pickup_datetime  fare_amount  fare_class  pickup_longitude  \\\n",
       "0  2010-04-19 08:17:56 UTC          6.5           0        -73.992365   \n",
       "1  2010-04-17 15:43:53 UTC          6.9           0        -73.990078   \n",
       "2  2010-04-17 11:23:26 UTC         10.1           1        -73.994149   \n",
       "3  2010-04-11 21:25:03 UTC          8.9           0        -73.990485   \n",
       "4  2010-04-17 02:19:01 UTC         19.7           1        -73.990976   \n",
       "\n",
       "   pickup_latitude  dropoff_longitude  dropoff_latitude  passenger_count  \\\n",
       "0        40.730521         -73.975499         40.744746                1   \n",
       "1        40.740558         -73.974232         40.744114                1   \n",
       "2        40.751118         -73.960064         40.766235                2   \n",
       "3        40.756422         -73.971205         40.748192                1   \n",
       "4        40.734202         -73.905956         40.743115                1   \n",
       "\n",
       "    dist_km  \n",
       "0  2.126312  \n",
       "1  1.392307  \n",
       "2  3.326763  \n",
       "3  1.864129  \n",
       "4  7.231321  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['dist_km'] = haversine_distance(df,'pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>fare_class</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>dist_km</th>\n",
       "      <th>EDTdate</th>\n",
       "      <th>Hour</th>\n",
       "      <th>AMorPM</th>\n",
       "      <th>Weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-04-19 08:17:56 UTC</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.992365</td>\n",
       "      <td>40.730521</td>\n",
       "      <td>-73.975499</td>\n",
       "      <td>40.744746</td>\n",
       "      <td>1</td>\n",
       "      <td>2.126312</td>\n",
       "      <td>2010-04-19 04:17:56</td>\n",
       "      <td>4</td>\n",
       "      <td>am</td>\n",
       "      <td>Mon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-04-17 15:43:53 UTC</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.990078</td>\n",
       "      <td>40.740558</td>\n",
       "      <td>-73.974232</td>\n",
       "      <td>40.744114</td>\n",
       "      <td>1</td>\n",
       "      <td>1.392307</td>\n",
       "      <td>2010-04-17 11:43:53</td>\n",
       "      <td>11</td>\n",
       "      <td>am</td>\n",
       "      <td>Sat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-04-17 11:23:26 UTC</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.994149</td>\n",
       "      <td>40.751118</td>\n",
       "      <td>-73.960064</td>\n",
       "      <td>40.766235</td>\n",
       "      <td>2</td>\n",
       "      <td>3.326763</td>\n",
       "      <td>2010-04-17 07:23:26</td>\n",
       "      <td>7</td>\n",
       "      <td>am</td>\n",
       "      <td>Sat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-04-11 21:25:03 UTC</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.990485</td>\n",
       "      <td>40.756422</td>\n",
       "      <td>-73.971205</td>\n",
       "      <td>40.748192</td>\n",
       "      <td>1</td>\n",
       "      <td>1.864129</td>\n",
       "      <td>2010-04-11 17:25:03</td>\n",
       "      <td>17</td>\n",
       "      <td>pm</td>\n",
       "      <td>Sun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-04-17 02:19:01 UTC</td>\n",
       "      <td>19.7</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.990976</td>\n",
       "      <td>40.734202</td>\n",
       "      <td>-73.905956</td>\n",
       "      <td>40.743115</td>\n",
       "      <td>1</td>\n",
       "      <td>7.231321</td>\n",
       "      <td>2010-04-16 22:19:01</td>\n",
       "      <td>22</td>\n",
       "      <td>pm</td>\n",
       "      <td>Fri</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pickup_datetime  fare_amount  fare_class  pickup_longitude  \\\n",
       "0  2010-04-19 08:17:56 UTC          6.5           0        -73.992365   \n",
       "1  2010-04-17 15:43:53 UTC          6.9           0        -73.990078   \n",
       "2  2010-04-17 11:23:26 UTC         10.1           1        -73.994149   \n",
       "3  2010-04-11 21:25:03 UTC          8.9           0        -73.990485   \n",
       "4  2010-04-17 02:19:01 UTC         19.7           1        -73.990976   \n",
       "\n",
       "   pickup_latitude  dropoff_longitude  dropoff_latitude  passenger_count  \\\n",
       "0        40.730521         -73.975499         40.744746                1   \n",
       "1        40.740558         -73.974232         40.744114                1   \n",
       "2        40.751118         -73.960064         40.766235                2   \n",
       "3        40.756422         -73.971205         40.748192                1   \n",
       "4        40.734202         -73.905956         40.743115                1   \n",
       "\n",
       "    dist_km             EDTdate  Hour AMorPM Weekday  \n",
       "0  2.126312 2010-04-19 04:17:56     4     am     Mon  \n",
       "1  1.392307 2010-04-17 11:43:53    11     am     Sat  \n",
       "2  3.326763 2010-04-17 07:23:26     7     am     Sat  \n",
       "3  1.864129 2010-04-11 17:25:03    17     pm     Sun  \n",
       "4  7.231321 2010-04-16 22:19:01    22     pm     Fri  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['EDTdate'] = pd.to_datetime(df['pickup_datetime'].str[:19]) - pd.Timedelta(hours=4)\n",
    "df['Hour'] = df['EDTdate'].dt.hour\n",
    "df['AMorPM'] = np.where(df['Hour']<12,'am','pm')\n",
    "df['Weekday'] = df['EDTdate'].dt.strftime(\"%a\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['Hour', 'AMorPM', 'Weekday']\n",
    "cont_cols = ['pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude', 'passenger_count', 'dist_km']\n",
    "y_col = ['fare_class']  # this column contains the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert our three categorical columns to category dtypes.\n",
    "for cat in cat_cols:\n",
    "    df[cat] = df[cat].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4,  0,  1],\n",
       "       [11,  0,  2],\n",
       "       [ 7,  0,  2],\n",
       "       [17,  1,  3],\n",
       "       [22,  1,  0]], dtype=int8)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hr = df['Hour'].cat.codes.values\n",
    "ampm = df['AMorPM'].cat.codes.values\n",
    "wkdy = df['Weekday'].cat.codes.values\n",
    "\n",
    "cats = np.stack([hr, ampm, wkdy], 1)\n",
    "\n",
    "cats[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4,  0,  1],\n",
       "        [11,  0,  2],\n",
       "        [ 7,  0,  2],\n",
       "        [17,  1,  3],\n",
       "        [22,  1,  0]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert categorical variables to a tensor\n",
    "cats = torch.tensor(cats, dtype=torch.int64)\n",
    "# this syntax is ok, since the source data is an array, not an existing tensor\n",
    "\n",
    "cats[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 40.7305, -73.9924,  40.7447, -73.9755,   1.0000,   2.1263],\n",
       "        [ 40.7406, -73.9901,  40.7441, -73.9742,   1.0000,   1.3923],\n",
       "        [ 40.7511, -73.9941,  40.7662, -73.9601,   2.0000,   3.3268],\n",
       "        [ 40.7564, -73.9905,  40.7482, -73.9712,   1.0000,   1.8641],\n",
       "        [ 40.7342, -73.9910,  40.7431, -73.9060,   1.0000,   7.2313]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert continuous variables to a tensor\n",
    "conts = np.stack([df[col].values for col in cont_cols], 1)\n",
    "conts = torch.tensor(conts, dtype=torch.float)\n",
    "conts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert labels to a tensor\n",
    "y = torch.tensor(df[y_col].values).flatten()\n",
    "\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120000, 3])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120000, 6])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120000])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(24, 12), (2, 1), (7, 4)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This will set embedding sizes for Hours, AMvsPM and Weekdays\n",
    "cat_szs = [len(df[col].cat.categories) for col in cat_cols]\n",
    "emb_szs = [(size, min(50, (size+1)//2)) for size in cat_szs]\n",
    "emb_szs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularModel(nn.Module):\n",
    "\n",
    "    def __init__(self, emb_szs, n_cont, out_sz, layers, p=0.5):\n",
    "        super().__init__()\n",
    "        self.embeds = nn.ModuleList([nn.Embedding(ni, nf) for ni,nf in emb_szs])\n",
    "        self.emb_drop = nn.Dropout(p)\n",
    "        self.bn_cont = nn.BatchNorm1d(n_cont)\n",
    "        \n",
    "        layerlist = []\n",
    "        n_emb = sum((nf for ni,nf in emb_szs))\n",
    "        n_in = n_emb + n_cont\n",
    "        \n",
    "        for i in layers:\n",
    "            layerlist.append(nn.Linear(n_in,i)) \n",
    "            layerlist.append(nn.ReLU(inplace=True))\n",
    "            layerlist.append(nn.BatchNorm1d(i))\n",
    "            layerlist.append(nn.Dropout(p))\n",
    "            n_in = i\n",
    "        layerlist.append(nn.Linear(layers[-1],out_sz))\n",
    "            \n",
    "        self.layers = nn.Sequential(*layerlist)\n",
    "    \n",
    "    def forward(self, x_cat, x_cont):\n",
    "        embeddings = []\n",
    "        for i,e in enumerate(self.embeds):\n",
    "            embeddings.append(e(x_cat[:,i]))\n",
    "        x = torch.cat(embeddings, 1)\n",
    "        x = self.emb_drop(x)\n",
    "        \n",
    "        x_cont = self.bn_cont(x_cont)\n",
    "        x = torch.cat([x, x_cont], 1)\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(33)\n",
    "model = TabularModel(emb_szs, conts.shape[1], 2, [200,100], p=0.4) # out_sz = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TabularModel(\n",
       "  (embeds): ModuleList(\n",
       "    (0): Embedding(24, 12)\n",
       "    (1): Embedding(2, 1)\n",
       "    (2): Embedding(7, 4)\n",
       "  )\n",
       "  (emb_drop): Dropout(p=0.4)\n",
       "  (bn_cont): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=23, out_features=200, bias=True)\n",
       "    (1): ReLU(inplace)\n",
       "    (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.4)\n",
       "    (4): Linear(in_features=200, out_features=100, bias=True)\n",
       "    (5): ReLU(inplace)\n",
       "    (6): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Dropout(p=0.4)\n",
       "    (8): Linear(in_features=100, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 60000\n",
    "test_size = 12000\n",
    "\n",
    "cat_train = cats[:batch_size-test_size]\n",
    "cat_test = cats[batch_size-test_size:batch_size]\n",
    "con_train = conts[:batch_size-test_size]\n",
    "con_test = conts[batch_size-test_size:batch_size]\n",
    "y_train = y[:batch_size-test_size]\n",
    "y_test = y[batch_size-test_size:batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   1  loss: 0.73441482\n",
      "epoch:  26  loss: 0.45090991\n",
      "epoch:  51  loss: 0.35915938\n",
      "epoch:  76  loss: 0.31940848\n",
      "epoch: 101  loss: 0.29913244\n",
      "epoch: 126  loss: 0.28824982\n",
      "epoch: 151  loss: 0.28091952\n",
      "epoch: 176  loss: 0.27713534\n",
      "epoch: 201  loss: 0.27236161\n",
      "epoch: 226  loss: 0.27171907\n",
      "epoch: 251  loss: 0.26830241\n",
      "epoch: 276  loss: 0.26365638\n",
      "epoch: 300  loss: 0.25949642\n",
      "\n",
      "Duration: 1275 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "epochs = 300\n",
    "losses = []\n",
    "\n",
    "for i in range(epochs):\n",
    "    i+=1\n",
    "    y_pred = model(cat_train, con_train)\n",
    "    loss = criterion(y_pred, y_train)\n",
    "    losses.append(loss)\n",
    "    \n",
    "    # a neat trick to save screen space:\n",
    "    if i%25 == 1:\n",
    "        print(f'epoch: {i:3}  loss: {loss.item():10.8f}')\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(f'epoch: {i:3}  loss: {loss.item():10.8f}') # print the last line\n",
    "print(f'\\nDuration: {time.time() - start_time:.0f} seconds') # print the time elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(epochs), losses)\n",
    "plt.ylabel('Cross Entropy Loss')\n",
    "plt.xlabel('epoch');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CE Loss: 0.25455481\n"
     ]
    }
   ],
   "source": [
    "# TO EVALUATE THE ENTIRE TEST SET\n",
    "with torch.no_grad():\n",
    "    y_val = model(cat_test, con_test)\n",
    "    loss = criterion(y_val, y_test)\n",
    "print(f'CE Loss: {loss:.8f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL OUTPUT               ARGMAX  Y_TEST\n",
      "tensor([ 1.8140, -1.6443])    0      0   \n",
      "tensor([-1.8268,  2.6373])    1      0   \n",
      "tensor([ 1.4028, -1.9248])    0      0   \n",
      "tensor([-1.9130,  1.4853])    1      1   \n",
      "tensor([ 1.1757, -2.4964])    0      0   \n",
      "tensor([ 2.0996, -2.2990])    0      0   \n",
      "tensor([ 1.3226, -1.8349])    0      0   \n",
      "tensor([-1.6211,  2.3889])    1      1   \n",
      "tensor([ 2.2489, -2.4253])    0      0   \n",
      "tensor([-0.4459,  1.1358])    1      1   \n",
      "tensor([ 1.5145, -2.1619])    0      0   \n",
      "tensor([ 0.7704, -1.9443])    0      0   \n",
      "tensor([ 0.9637, -1.3796])    0      0   \n",
      "tensor([-1.3527,  1.7322])    1      1   \n",
      "tensor([ 1.4110, -2.4595])    0      0   \n",
      "tensor([-1.4455,  2.6081])    1      1   \n",
      "tensor([ 2.2798, -2.5864])    0      1   \n",
      "tensor([ 1.4585, -2.7982])    0      0   \n",
      "tensor([ 0.3342, -0.8995])    0      0   \n",
      "tensor([ 2.0525, -1.9737])    0      0   \n",
      "tensor([-1.3571,  2.1911])    1      1   \n",
      "tensor([-0.4669,  0.2872])    1      1   \n",
      "tensor([-2.0624,  2.2875])    1      1   \n",
      "tensor([-2.1334,  2.6416])    1      1   \n",
      "tensor([-3.1325,  5.1561])    1      1   \n",
      "tensor([ 2.2128, -2.5172])    0      0   \n",
      "tensor([ 1.0346, -1.7764])    0      0   \n",
      "tensor([ 1.1221, -1.6717])    0      0   \n",
      "tensor([-2.1322,  1.6714])    1      1   \n",
      "tensor([ 1.5009, -1.6338])    0      0   \n",
      "tensor([ 2.0387, -1.8475])    0      0   \n",
      "tensor([-1.6346,  2.8899])    1      1   \n",
      "tensor([-3.0129,  2.3519])    1      1   \n",
      "tensor([-1.5746,  2.0000])    1      1   \n",
      "tensor([ 1.3056, -2.2630])    0      0   \n",
      "tensor([ 0.6631, -1.4797])    0      0   \n",
      "tensor([-1.4585,  2.1836])    1      1   \n",
      "tensor([ 1.0574, -1.5848])    0      1   \n",
      "tensor([ 0.3376, -0.8050])    0      1   \n",
      "tensor([ 1.9217, -1.9764])    0      0   \n",
      "tensor([ 0.1011, -0.5529])    0      0   \n",
      "tensor([ 0.6703, -0.5540])    0      0   \n",
      "tensor([-0.6733,  0.8777])    1      1   \n",
      "tensor([ 2.2017, -2.0445])    0      0   \n",
      "tensor([-0.0442, -0.4276])    0      0   \n",
      "tensor([-1.1204,  1.2558])    1      1   \n",
      "tensor([-1.8170,  2.7124])    1      1   \n",
      "tensor([ 1.7404, -2.0341])    0      0   \n",
      "tensor([ 1.3266, -2.3039])    0      0   \n",
      "tensor([-0.0671,  0.3291])    1      0   \n",
      "\n",
      "45 out of 50 = 90.00% correct\n"
     ]
    }
   ],
   "source": [
    "rows = 50\n",
    "correct = 0\n",
    "print(f'{\"MODEL OUTPUT\":26} ARGMAX  Y_TEST')\n",
    "for i in range(rows):\n",
    "    print(f'{str(y_val[i]):26} {y_val[i].argmax():^7}{y_test[i]:^7}')\n",
    "    if y_val[i].argmax().item() == y_test[i]:\n",
    "        correct += 1\n",
    "print(f'\\n{correct} out of {rows} = {100*correct/rows:.2f}% correct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure to save the model only after the training has happened!\n",
    "if len(losses) == epochs:\n",
    "    torch.save(model.state_dict(), 'TaxiFareClssModel.pt')\n",
    "else:\n",
    "    print('Model has not been trained. Consider loading a trained model instead.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def haversine_distance(df, lat1, long1, lat2, long2):\n",
    "    r = 6371\n",
    "    phi1 = np.radians(df[lat1])\n",
    "    phi2 = np.radians(df[lat2])\n",
    "    delta_phi = np.radians(df[lat2]-df[lat1])\n",
    "    delta_lambda = np.radians(df[long2]-df[long1])\n",
    "    a = np.sin(delta_phi/2)**2 + np.cos(phi1) * np.cos(phi2) * np.sin(delta_lambda/2)**2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n",
    "    return r * c\n",
    "\n",
    "class TabularModel(nn.Module):\n",
    "    def __init__(self, emb_szs, n_cont, out_sz, layers, p=0.5):\n",
    "        super().__init__()\n",
    "        self.embeds = nn.ModuleList([nn.Embedding(ni, nf) for ni,nf in emb_szs])\n",
    "        self.emb_drop = nn.Dropout(p)\n",
    "        self.bn_cont = nn.BatchNorm1d(n_cont)\n",
    "        layerlist = []\n",
    "        n_emb = sum((nf for ni,nf in emb_szs))\n",
    "        n_in = n_emb + n_cont\n",
    "        for i in layers:\n",
    "            layerlist.append(nn.Linear(n_in,i)) \n",
    "            layerlist.append(nn.ReLU(inplace=True))\n",
    "            layerlist.append(nn.BatchNorm1d(i))\n",
    "            layerlist.append(nn.Dropout(p))\n",
    "            n_in = i\n",
    "        layerlist.append(nn.Linear(layers[-1],out_sz))\n",
    "        self.layers = nn.Sequential(*layerlist)\n",
    "    def forward(self, x_cat, x_cont):\n",
    "        embeddings = []\n",
    "        for i,e in enumerate(self.embeds):\n",
    "            embeddings.append(e(x_cat[:,i]))\n",
    "        x = torch.cat(embeddings, 1)\n",
    "        x = self.emb_drop(x)\n",
    "        x_cont = self.bn_cont(x_cont)\n",
    "        x = torch.cat([x, x_cont], 1)\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_szs = [(24, 12), (2, 1), (7, 4)]\n",
    "model2 = TabularModel(emb_szs, 6, 2, [200,100], p=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TabularModel(\n",
       "  (embeds): ModuleList(\n",
       "    (0): Embedding(24, 12)\n",
       "    (1): Embedding(2, 1)\n",
       "    (2): Embedding(7, 4)\n",
       "  )\n",
       "  (emb_drop): Dropout(p=0.4)\n",
       "  (bn_cont): BatchNorm1d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=23, out_features=200, bias=True)\n",
       "    (1): ReLU(inplace)\n",
       "    (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.4)\n",
       "    (4): Linear(in_features=200, out_features=100, bias=True)\n",
       "    (5): ReLU(inplace)\n",
       "    (6): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Dropout(p=0.4)\n",
       "    (8): Linear(in_features=100, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.load_state_dict(torch.load('TaxiFareClssModel.pt'));\n",
    "model2.eval() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_data(mdl): # pass in the name of the new model\n",
    "    # INPUT NEW DATA\n",
    "    plat = float(input('What is the pickup latitude?  '))\n",
    "    plong = float(input('What is the pickup longitude? '))\n",
    "    dlat = float(input('What is the dropoff latitude?  '))\n",
    "    dlong = float(input('What is the dropoff longitude? '))\n",
    "    psngr = int(input('How many passengers? '))\n",
    "    dt = input('What is the pickup date and time?\\nFormat as YYYY-MM-DD HH:MM:SS     ')\n",
    "    \n",
    "    # PREPROCESS THE DATA\n",
    "    dfx_dict = {'pickup_latitude':plat,'pickup_longitude':plong,'dropoff_latitude':dlat,\n",
    "         'dropoff_longitude':dlong,'passenger_count':psngr,'EDTdate':dt}\n",
    "    dfx = pd.DataFrame(dfx_dict, index=[0])\n",
    "    dfx['dist_km'] = haversine_distance(dfx,'pickup_latitude', 'pickup_longitude',\n",
    "                                        'dropoff_latitude', 'dropoff_longitude')\n",
    "    dfx['EDTdate'] = pd.to_datetime(dfx['EDTdate'])\n",
    "    \n",
    "    # We can skip the .astype(category) step since our fields are small,\n",
    "    # and encode them right away\n",
    "    dfx['Hour'] = dfx['EDTdate'].dt.hour\n",
    "    dfx['AMorPM'] = np.where(dfx['Hour']<12,0,1) \n",
    "    dfx['Weekday'] = dfx['EDTdate'].dt.strftime(\"%a\")\n",
    "    dfx['Weekday'] = dfx['Weekday'].replace(['Fri','Mon','Sat','Sun','Thu','Tue','Wed'],\n",
    "                                            [0,1,2,3,4,5,6]).astype('int64')\n",
    "    # CREATE CAT AND CONT TENSORS\n",
    "    cat_cols = ['Hour', 'AMorPM', 'Weekday']\n",
    "    cont_cols = ['pickup_latitude', 'pickup_longitude', 'dropoff_latitude',\n",
    "                 'dropoff_longitude', 'passenger_count', 'dist_km']\n",
    "    xcats = np.stack([dfx[col].values for col in cat_cols], 1)\n",
    "    xcats = torch.tensor(xcats, dtype=torch.int64)\n",
    "    xconts = np.stack([dfx[col].values for col in cont_cols], 1)\n",
    "    xconts = torch.tensor(xconts, dtype=torch.float)\n",
    "    \n",
    "    # PASS NEW DATA THROUGH THE MODEL WITHOUT PERFORMING A BACKPROP\n",
    "    with torch.no_grad():\n",
    "        z = mdl(xcats, xconts).argmax().item()\n",
    "    print(f'\\nThe predicted fare class is {z}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed new data through the trained model\n",
    "\n",
    "For convenience, here are the max and min values for each of the variables:\n",
    "<table style=\"display: inline-block\">\n",
    "<tr><th>Column</th><th>Minimum</th><th>Maximum</th></tr>\n",
    "<tr><td>pickup_latitude</td><td>40</td><td>41</td></tr>\n",
    "<tr><td>pickup_longitude</td><td>-74.5</td><td>-73.3</td></tr>\n",
    "<tr><td>dropoff_latitude</td><td>40</td><td>41</td></tr>\n",
    "<tr><td>dropoff_longitude</td><td>-74.5</td><td>-73.3</td></tr>\n",
    "<tr><td>passenger_count</td><td>1</td><td>5</td></tr>\n",
    "<tr><td>EDTdate</td><td>2010-04-11 00:00:00</td><td>2010-04-24 23:59:42</td></tr>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the pickup latitude?  40.5\n",
      "What is the pickup longitude? -73.9\n",
      "What is the dropoff latitude?  40.52\n",
      "What is the dropoff longitude? -73.92\n",
      "How many passengers? 2\n",
      "What is the pickup date and time?\n",
      "Format as YYYY-MM-DD HH:MM:SS     2010-04-15 16:00:00\n",
      "\n",
      "The predicted fare class is 1\n"
     ]
    }
   ],
   "source": [
    "test_data(model2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
